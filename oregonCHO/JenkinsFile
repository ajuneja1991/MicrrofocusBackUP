import java.text.SimpleDateFormat

if (env.BRANCH_NAME == null){
  // if build is triggered from another build, the branch name is set to null. We're assuming master here, as we're only triggering builds from master
  env.BRANCH_NAME == 'master';
}

if (env.BRANCH_NAME ==~ /^\d{2}\.\d{2}\/hf$/){
  library 'bvd-jenkins-library@'+env.BRANCH_NAME
  MASTER_BRANCH = env.BRANCH_NAME
} else {
  library 'bvd-jenkins-library'
}

/* Global definitions */
def SSH_GLOBAL_OPTIONS = "-o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o CheckHostIP=no -i ssh_key.pem"
def TESTREPORTSRV = 'orelinci004.itom.aws.swinfra.net'
def currentStage = 'Jenkins'
def additionalEmailText = ''
def testDBType = getTestDBType()
def versionInformation = ''
def emailSubject = ''
def dateFormat = new SimpleDateFormat("yyyyMMddHHmm")
def start_date = new Date()
def start_date_string = dateFormat.format(start_date)
def REPORT_FOLDER = start_date_string
def Suite_Url = ""
def cypressStartOfTheWeek=""
def ACCESSVM = ''

parameters {
  string(defaultValue: 'master', description: 'Branch Name', name: 'BRANCH_NAME')
  string(defaultValue: '443', description: 'BVD Port', name: 'BVD_PORT')
  booleanParam(defaultValue: true, description: 'Check to deploy New System', name: 'DEPLOY_SYSTEM')
  booleanParam(defaultValue: true, description: 'Start CDF and OpsB Chart Installation', name: 'INSTALL')
  booleanParam(defaultValue: true, description: 'Check to run the Cypress UI tests', name: 'RUN_CYPRESS_UI_TESTS')
  booleanParam(defaultValue: true, description: 'Check to install suite Licenses', name: 'INSTALL_SUITE_LICENSES')
  booleanParam(defaultValue: true, description: 'Check to collect coverage', name: 'COLLECT_COVERAGE')
  booleanParam(defaultValue: true, description: 'Check to set up prometheus', name: 'SETUP_PROMETHEUS')
  string(defaultValue: 'bvdcho-7c44.aws.swinfra.net', description: 'External Postgres Hostname', name: 'PG_HOSTNAME')
  string(defaultValue: 'Monday,Tuesday,Wednesday,Thursday,Friday,Saturday', description: 'The days of week on which the test will be triggered with external PostgreSQL', name: 'EXTERNAL_PG_SCHEDULE')
  string(defaultValue: 'server_cho.crt', description: 'Provide the Postgres Cert File Name', name: 'POSTGRES_CERT')
  string(defaultValue: '10.168.179.57', description: 'Provide Port of Vertica Database', name: 'VERTICA_HOSTNAME')
  string(defaultValue: '5433', description: 'Provide Port Number of Vertica Database', name: 'VERTICA_DB_PORT' )
}

try {
  ansiColor('xterm') {
    /* defaults */
    def label = "bvd-test-pod-ci-farm-${UUID.randomUUID().toString()}"
    def BODA_BASE_DIR = "/boda"
    def EC_SUITE = "SuiteBVD"
    def BVD_VERSION = ""
    def SSHINTOSYSTEM_FILE = ""
    def FILE = ""
    def DEPLOY_SCRIPT = ""
    def OB_HOME = "/tmp/OB_HOME"
    def PV_NAME = ""
    def LICENSE_FILE_PREMIUM = ""
    def LICENSE_FILE_ULTIMATE = ""
    def LICENSE_SCRIPT = ""
    def WEB2PDF_SCRIPT = ""
    def LICENSE_SCRIPT_PATH = ""
    def POLLPROMETHEUSPOD_FILE = ""
    def TYPE = "SIT"
    def PORT = "22"
    def BVDPORT = "443"
    def STESTLOG = "/tmp/HPOpr${TYPE}_${UUID.randomUUID().toString()}.log"
    def SANITY_SYSTEM_HOSTNAME = ""
    def CDFINSTALL_FILE = ""
    def CDF_PODS_POLL_FILE =""
    def CDFINSTALL_SCRIPT =""
    def SYSTEM_HOSTNAME = ""
    def POSTGRES_CERT_PATH = ""
    def UPLOAD_WELCOME_SCRIPT = ""
    def WELCOME_DASHBOARD_FILE = ""
    def DB_CONNECTION_FILE = ""

    // Will wait for 7 hours max
    timeout(time:620, unit: 'MINUTES') {
      podTemplate( label: label, cloud: 'kubernetes',
        containers: [ templateNodeBuild(), templateAWS(), templateHelm(), templateDryRun(), templateCDFarm() ],
        volumes: [
          hostPathVolume(mountPath: '/var/run/docker.sock', hostPath: '/var/run/docker.sock'),
          secretVolume(secretName: 'opc-bld-ssh', mountPath: '/sshid', defaultMode: '256'),
          nfsVolume(mountPath: '/boda', serverAddress: 'fs-06e41936fa598f287.efs.us-west-2.amazonaws.com', serverPath: '/sftp/pub', readOnly: false),
		      nfsVolume(mountPath: '/boda_data', serverAddress: 'fs-06e41936fa598f287.efs.us-west-2.amazonaws.com', serverPath: '/btl', readOnly: true),
          nfsVolume(mountPath: '/report', serverAddress: 'fs-0d0247a7e3888419c.efs.us-west-2.amazonaws.com', serverPath: '/', readOnly: false),
        ]
      )
      {
        node(label) {
          stage('checkout') {
            container('node-build') {
              banner("checkout")
              checkout scm
              branch = env.BRANCH_NAME

              sh """
                curl ${globals.ARTIFACTORY_URL}itom-buildoutput/uis/${globals.BVD_VERSION}/helm-chart.version -o ${WORKSPACE}/helm-chart.version
                curl ${globals.ARTIFACTORY_URL}itom-buildoutput/uis/${globals.BVD_VERSION}/helm-chart.commit -o ${WORKSPACE}/helm-chart.commit
              """
              BVD_CHART_VERSION  = sh(script: "head -n 1 ${WORKSPACE}/helm-chart.version", returnStdout: true).trim()
              COMMIT_HASH = sh(script: "head -n 1 ${WORKSPACE}/helm-chart.commit", returnStdout: true).trim()
              sh "git checkout ${COMMIT_HASH}"
              BVD_VERSION = BVD_CHART_VERSION

              BVD_PODS_POLL_FILE = "./build/tests/bvdPodsPoll.sh"
              CDF_PODS_POLL_FILE = "./build/tests/cdfPodsPoll.sh"
              USER_ROLE_JSON_FILE = "./build/tests/com.microfocus.cdf__2020.05__Add_Update_User.json"
              WELCOME_DASHBOARD_FILE = "./build/tests/Welcome.bvd"
              UPLOAD_WELCOME_SCRIPT = "./build/tests/uploadWelcome.sh"
              DB_CONNECTION_FILE = "./build/tests/dbconnection.json"
              SSHINTOSYSTEM_FILE = "./build/tests/testSystemBeforeDoingSCP.sh"
              DEPLOY_SCRIPT = "opsbDeploy.sh"
              DEPLOY_SCRIPT_FULL_PATH = "./build/tests/${DEPLOY_SCRIPT}"
              LICENSE_FILE_PREMIUM = "./build/tests/NOM-licfile-Premium.xml"
              LICENSE_FILE_ULTIMATE = "./build/tests/NOM-licfile-Ultimate.xml"
              LICENSE_SCRIPT = "license_script.sh"
              LICENSE_SCRIPT_PATH = "./build/tests/${LICENSE_SCRIPT}"
              CDFINSTALL_FILE = "./build/tests/cdfInstall.sh"
              CDFINSTALL_SCRIPT = "cdfInstall.sh"
              WEB2PDF_SCRIPT = "./build/tests/webtopdf/webtopdf_parallelrequests.sh"
              POLLPROMETHEUSPOD_FILE = "./build/tests/pollPrometheusPods.sh"
              POSTGRES_CERT_PATH = "./build/tests/${POSTGRES_CERT}"
              echo "-->Build ${BVD_VERSION}<--"
              echo "-->Branch ${branch}<--"

              FINAL_IMG_DIR = "${WORKSPACE}/finalBuild"

              configFileProvider([configFile(fileId: '24339076-7756-4f3d-9e19-3e9c5efa4fe7' , variable: 'ssh_key_file')]){
                 sh "cat ${env.ssh_key_file} > ssh_key.pem"
              }

              sh """
                cd ${WORKSPACE}
                chmod 600 ssh_key.pem
                cat ssh_key.pem
              """

              sh  """
                rm -rf /tmp/conf.env
                pwd
                mkdir -p ${FINAL_IMG_DIR}
              """
            }
          }

          stage('Deploy System') {
            if (DEPLOY_SYSTEM == 'true') {
              container('cdfarm') {
              try {
              def random_id = sh(script: "tr -dc A-Za-z </dev/urandom | head -c 5 ; echo ''", returnStdout: true)
              def build_id = "BVDCHO-"
              build_id  = build_id.concat(random_id);
              configFileProvider([configFile(fileId: '365f5084-cd78-4f9b-a07b-8187dac442cd', variable: 'Lambda_payload')]) {
                sh """
                cat ${env.Lambda_payload} > deploy.json
		            echo ${build_id}
                build_id=${build_id}
		            echo \$build_id > build_id.txt
		            cat build_id.txt
                echo "INFO: BUILD_ID is \$build_id"
                sed -i -e "s/<BUILD_ID>/\$build_id/g" deploy.json
                cat deploy.json
              """
                currentBuild.description = "Build ID:${build_id}"

                sh """
                aws sts assume-role --role-arn arn:aws:iam::486778422851:role/Assume_Lambda_Invoke --role-session-name service-catalog-api > Assume-Role.json
                if [ \$? -ne 0 ] ; then
                  echo "Error: Role is Not Assumed Successfully"
                  exit 1
                else
                  echo "INFO: Role is Assumed Successfully"
                  MyAccessKeyId=`cat Assume-Role.json | jq -r '.Credentials.AccessKeyId'`
                  MySecretAccessKey=`cat Assume-Role.json | jq -r '.Credentials.SecretAccessKey'`
                  MySessionToken=`cat Assume-Role.json | jq -r '.Credentials.SessionToken'`
                  export AWS_ACCESS_KEY_ID=\$MyAccessKeyId
                  export AWS_SECRET_ACCESS_KEY=\$MySecretAccessKey
                  export AWS_SESSION_TOKEN=\$MySessionToken
                  export AWS_DEFAULT_REGION=us-west-2
                fi
                aws lambda invoke --function-name service-catalog-api --cli-binary-format raw-in-base64-out --payload file://deploy.json response.json
                if [ \$? -ne 0 ] ; then
                 echo "Error: Failed to Invoke Lambda"
                 cat response.json
                 exit 1
                else
                 echo "INFO: Invoked Lambda successfully"
                 cat response.json
                fi
              """

              sh """
                aws sts assume-role --role-arn arn:aws:iam::486778422851:role/Assume_Lambda_Invoke --role-session-name service-catalog-api > Assume-Role.json
                if [ \$? -ne 0 ] ; then
                  echo "Error: Role is Not Assumed Successfully"
                  exit 1
                else
                  echo "INFO: Role is Assumed Successfully"
                  MyAccessKeyId=`cat Assume-Role.json | jq -r '.Credentials.AccessKeyId'`
                  MySecretAccessKey=`cat Assume-Role.json | jq -r '.Credentials.SecretAccessKey'`
                  MySessionToken=`cat Assume-Role.json | jq -r '.Credentials.SessionToken'`
                  export AWS_ACCESS_KEY_ID=\$MyAccessKeyId
                  export AWS_SECRET_ACCESS_KEY=\$MySecretAccessKey
                  export AWS_SESSION_TOKEN=\$MySessionToken
                  export AWS_DEFAULT_REGION=us-west-2
                fi
                echo "To check the status"
		            build_id=\$( cat build_id.txt)
                echo "{\n\\"step\\": \\"status\\",\n\\"buildid\\": \\"\$build_id\\"\n}" > status.json
		            cat status.json
                aws lambda invoke --function-name service-catalog-api --cli-binary-format raw-in-base64-out --payload file://status.json status-response.json
                 if [ \$? -ne 0 ] ; then
                 echo "Error: Failed to invoke Lambda function to get the status"
                 cat status-response.json
                 exit 1
                 else
                 echo "INFO: Invoked Lambda successfully to get the status"
                 #cat status-response.json
                status=\$(cat status-response.json | jq -r .Status)
                while [ \$status = "UNDER_CHANGE" ]
                  do
                    echo "waiting for resources to get provisioned"
                    sleep 50
                    aws lambda invoke --function-name service-catalog-api --cli-binary-format raw-in-base64-out --payload file://status.json status-response.json
                    status=\$(cat status-response.json  | jq -r .Status)
                  done
                  echo "INFO: Resources are created and waiting for domain Joining"
                  sleep 600
                fi
              """
              sh """
                aws sts assume-role --role-arn arn:aws:iam::486778422851:role/Assume_Lambda_Invoke --role-session-name service-catalog-api > Assume-Role.json
                if [ \$? -ne 0 ] ; then
                  echo "Error: Role is Not Assumed Successfully"
                  exit 1
                else
                  echo "INFO: Role is Assumed Successfully"
                  MyAccessKeyId=`cat Assume-Role.json | jq -r '.Credentials.AccessKeyId'`
                  MySecretAccessKey=`cat Assume-Role.json | jq -r '.Credentials.SecretAccessKey'`
                  MySessionToken=`cat Assume-Role.json | jq -r '.Credentials.SessionToken'`
                  export AWS_ACCESS_KEY_ID=\$MyAccessKeyId
                  export AWS_SECRET_ACCESS_KEY=\$MySecretAccessKey
                  export AWS_SESSION_TOKEN=\$MySessionToken
                  export AWS_DEFAULT_REGION=us-west-2
                fi
                echo "To Get the Resource Details"
		            build_id=\$( cat build_id.txt)

                echo "{\n\\"step\\": \\"details\\",\n\\"buildid\\": \\"\$build_id\\"\n}" > details.json
                cat details.json
		            aws lambda invoke --function-name service-catalog-api --cli-binary-format raw-in-base64-out --payload file://details.json aws.json
                if [ \$? -ne 0 ] ; then
                 echo "Error: Failed to invoke Lambda function to get the Resource Details"
                 cat aws.json
                 exit 1
                else
                 echo "INFO: Invoked Lambda function successfully and got the resource details"
                 cat aws.json
                fi
                ACCESSVM=\$(cat aws.json | jq -r .bvdcho[].IpAddress)
              """
              ACCESSVM  = sh(script: "cat aws.json | jq -r .bvdcho[].IpAddress", returnStdout: true).trim()
              }
              }catch (e) {
                currentBuild.result = "UNSTABLE"
                echo "Error: System Deployment Failed"
                additionMsg = "[System Deployment failed]"
                }
              }
            }
          }

          stage('installCDF') {
            if (INSTALL == 'true') {
              container('general-aws') {
                banner("copy Files into AccessVM and Start CDF Installation")
                configFileProvider([configFile(fileId: '24339076-7756-4f3d-9e19-3e9c5efa4fe7' , variable: 'ssh_key_file')]){
                  sh "cat ${env.ssh_key_file} > ssh_key.pem"
                }
                sh """
                  cd ${WORKSPACE}
                  chmod 755 ${CDFINSTALL_FILE}
                  chmod 755 ${CDF_PODS_POLL_FILE}
                  chmod 755 ${LICENSE_FILE_PREMIUM}
                  chmod 755 ${LICENSE_FILE_ULTIMATE}
                  chmod 755 ${LICENSE_SCRIPT_PATH}
                  chmod 600 ssh_key.pem
                  cat ssh_key.pem
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
                  put ${CDFINSTALL_FILE} /tmp/
                  put ${CDF_PODS_POLL_FILE} /tmp/
                  put ${BVD_PODS_POLL_FILE} /tmp/
                  put ${LICENSE_FILE_PREMIUM} /tmp/
                  put ${LICENSE_FILE_ULTIMATE} /tmp/
                  put ${LICENSE_SCRIPT_PATH} /tmp/
                  bye
                """
                sh """
                  echo "CDF Prerequisites"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo sed -i 's/^ClientAliveInterval.*/ClientAliveInterval 3600/g' /etc/ssh/sshd_config; sudo sed -i 's/^ClientAliveCountMax.*/ClientAliveCountMax 0/g' /etc/ssh/sshd_config; sudo systemctl reload sshd;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; sudo chown root cdfInstall.sh cdfPodsPoll.sh; sudo chgrp root cdfInstall.sh cdfPodsPoll.sh;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo ./${CDFINSTALL_SCRIPT};"
                  echo "Installing CDF"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo cat cdfInstallCommand | sudo bash;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo ./cdfPodsPoll.sh;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; sudo chmod 777 kube-status.out; sudo chmod 777 result.html; cd /opt/kubernetes; sudo chmod 777 version.txt;"
                """
              }
              container('general-aws') {
                sh """
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
                  lcd /tmp
                  cd /tmp
                  get kube-status.out
                  get result.html
                  cd /opt/kubernetes
                  get version.txt
                  bye
                """
                statusMessage = sh(script: "grep 'K8S cluster is Running' /tmp/kube-status.out", returnStdout:true).trim()
                if (statusMessage != "K8S cluster is Running") {
                  additionalEmailText = additionalEmailText + sh(script: "cat /tmp/kube-status.out",returnStdout:true).trim()
                  throw new Exception("CDF pods are not up and running")
                }
                additionalEmailText = additionalEmailText + "CDF Version: " + sh(script: "cat /tmp/version.txt",returnStdout:true).trim() + " <br />"
              }
            }
          }

          stage('installChart') {
            if (INSTALL == 'true') {
              container('general-aws') {
                SYSTEM_HOSTNAME=sh(script: "ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} \"hostname -f\"",  returnStdout:true).trim()
                sh """
                  chmod 755 ${WELCOME_DASHBOARD_FILE}
                  chmod 755 ${UPLOAD_WELCOME_SCRIPT}
                  chmod 755 ${BVD_PODS_POLL_FILE}
                  chmod 755 ${POSTGRES_CERT_PATH}
                  chmod 755 ${USER_ROLE_JSON_FILE}
                  chmod 755 ${DEPLOY_SCRIPT_FULL_PATH}
                  export OB_HOME=${OB_HOME}
                  export PG_HOSTNAME="${PG_HOSTNAME}"
                  export BRANCH_NAME="${env.BRANCH_NAME}"
                  export EXTERNAL_PG_SCHEDULE="${EXTERNAL_PG_SCHEDULE}"
                  export POSTGRES_CERT="${POSTGRES_CERT}"
                  export VERTICA_HOSTNAME="${VERTICA_HOSTNAME}"
                  export VERTICA_DB_PORT="${VERTICA_DB_PORT}"
                  echo "CONF_EXTERNAL_ACCESS_PORT"="${BVD_PORT}" >> /tmp/conf.env
                  echo "BRANCH_NAME"="${env.BRANCH_NAME}" >> /tmp/conf.env
                  echo "PG_HOSTNAME"="${PG_HOSTNAME}" >> /tmp/conf.env
                  echo "EXTERNAL_PG_SCHEDULE"="${EXTERNAL_PG_SCHEDULE}" >> /tmp/conf.env
                  echo "POSTGRES_CERT"="${POSTGRES_CERT}" >> /tmp/conf.env
                  echo "VERTICA_HOSTNAME"="${VERTICA_HOSTNAME}" >> /tmp/conf.env
                  echo "VERTICA_DB_PORT"="${VERTICA_DB_PORT}" >> /tmp/conf.env
				          ssh -vvv ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; sudo mkdir -p ${OB_HOME}" || true
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; sudo mkdir -p ${OB_HOME}"
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
				          put ${WELCOME_DASHBOARD_FILE} /tmp/
                  put ${UPLOAD_WELCOME_SCRIPT} /tmp/
                  put ${DB_CONNECTION_FILE} /tmp/
                  put ${USER_ROLE_JSON_FILE} /tmp/
                  put ${POSTGRES_CERT_PATH} /tmp/
                  put ${BVD_PODS_POLL_FILE} /tmp/
                  put ${DEPLOY_SCRIPT_FULL_PATH} /tmp/
                  put /tmp/conf.env /tmp/
                  bye
                """
                sh """
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; sudo chown root:root conf.env; sudo chmod 777 conf.env"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; sudo chown root:root ${DEPLOY_SCRIPT}; sudo chmod 777 ${DEPLOY_SCRIPT}"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo ./${DEPLOY_SCRIPT} -h ${SYSTEM_HOSTNAME} -v ${BVD_VERSION} -t;"
                  # Adding sleep for allowing system to download images in AWS
                  sleep 900s
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; sudo chown root bvdPodsPoll.sh bvdPodsPoll.sh license_script.sh NOM-licfile-Premium.xml NOM-licfile-Ultimate.xml uploadWelcome.sh Welcome.bvd; sudo chgrp root bvdPodsPoll.sh bvdPodsPoll.sh license_script.sh NOM-licfile-Premium.xml NOM-licfile-Ultimate.xml uploadWelcome.sh Welcome.bvd;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo chmod 777 bvdPodsPoll.sh;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo ./bvdPodsPoll.sh ${BVD_PORT};"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; sudo chmod 777 bvd_pods_status.out; sudo chmod 777 result.html; cd /opt/kubernetes; sudo chmod 777 version.txt;"
                """
              }
              container('general-aws') {
                sh """
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
                  lcd /tmp
                  cd /tmp
                  get bvd_pods_status.out
                  get result.html
                  cd /opt/kubernetes
                  get version.txt
                  bye
                """
                statusMessage = sh(script: "grep 'BVD pods are up and running' /tmp/bvd_pods_status.out", returnStdout:true).trim()
                if (statusMessage != "BVD pods are up and running") {
                  additionalEmailText = additionalEmailText + sh(script: "cat /tmp/bvd_pods_status.out",returnStdout:true).trim()
                  throw new Exception("BVD pods are not up and running")
                }
                cypressStartOfTheWeek = getCurrentDay()
                sh """
                  chmod 755 ${LICENSE_FILE_PREMIUM}
                  chmod 755 ${LICENSE_FILE_ULTIMATE}
                  chmod 755 ${LICENSE_SCRIPT_PATH}
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
				          put ${LICENSE_FILE_PREMIUM} /tmp/
                  put ${LICENSE_FILE_ULTIMATE} /tmp/
                  put ${LICENSE_SCRIPT_PATH} /tmp/
                  bye
                """
                Suite_Url = "https://${SYSTEM_HOSTNAME}:${BVDPORT}"
                sh """
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; chmod 777 license_script.sh; sudo ./license_script.sh -u admin -p Control@123 -s ${Suite_Url}"
                """
                additionalEmailText = additionalEmailText + "CDF Version: " + sh(script: "cat /tmp/version.txt",returnStdout:true).trim() + " <br />"
                additionalEmailText = additionalEmailText + sh(script: "cat /tmp/result.html",returnStdout:true).trim()
              }
            }
          }

          if (RUN_CYPRESS_UI_TESTS == 'true') {
            stage('build:node') {
              try {
                container('node-build') {
                  banner("download node_modules")
                  sh """
                    cd dashboard
                    curl ${globals.ARTIFACTORY_URL}itom-buildoutput/uis/node_modules_dev/${globals.BVD_VERSION}/node_modules_dev-${globals.BVD_VERSION}.zip -o bvd_node_modules_devel-linux.zip
                    unzip -o bvd_node_modules_devel-linux.zip
                  """
                }
              } catch (error) {
                currentStage = STAGE_NAME
                throw error
              }
            }

            stage('copy:Plugins') {
              container('general-aws') {
                banner('copying custom plugins to nfs location')
                PV_NAME = sh(script:"ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} \"sudo find /var/vols/itom/ -path '*/bvd/var/bvd'\"", returnStdout:true).trim()
                sh """
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; sudo chown centos ${PV_NAME}/plugins; sudo chgrp centos ${PV_NAME}/plugins;"
                  #ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo chown -R centos:centos ${PV_NAME}/plugins;"
                """
                sh """
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
                  lcd ./dashboard/test/cypress/fixtures/plugins/
                  cd ${PV_NAME}/plugins/
				          put ./dashboard/test/cypress/fixtures/plugins ${PV_NAME}/plugins
				          put -r *
                  bye
                """
                sh """
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo chown -R root:root ${PV_NAME}/plugins;"
                """
              }
            }

            stage('test:Cypress') {
              container('node-build') {
                currentStage = STAGE_NAME
                banner('Cypress UI test')
                sh """
                  echo "Checking if Prometheus Pods are Up"
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
				          put ${POLLPROMETHEUSPOD_FILE} /tmp/
                  bye
                """
                sh """
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo chown root:root pollPrometheusPods.sh; sudo chmod 777 /tmp/pollPrometheusPods.sh"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo ./pollPrometheusPods.sh;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "cd /tmp; sudo chmod 777 prometheus_pods_status.out;"
                """
                sh """
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
                  lcd /tmp
                  cd /tmp
                  get prometheus_pods_status.out
                  bye
                """
                statusMessage = sh(script: "grep 'Prometheus pods are up and running' /tmp/prometheus_pods_status.out", returnStdout:true).trim()
                if (statusMessage != "Prometheus pods are up and running") {
                  additionalEmailText = additionalEmailText + sh(script: "cat /tmp/prometheus_pods_status.out",returnStdout:true).trim()
                  throw new Exception("Prometheus pods are not up and running")
                }
                cypressStartOfTheWeek = sh(script: "ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} 'sudo kubectl get cm bvd-config -n \$(sudo kubectl get ns | grep bvd- | cut -d \" \" -f 1) -o yaml | grep \"startOfTheWeek\" | cut -b 23-'", returnStdout: true).trim()
                wwwPodName = sh(script: "ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} 'sudo kubectl get pods -n \$(sudo kubectl get ns | grep bvd- | cut -d \" \" -f 1) | grep bvd-www | cut -d \" \" -f1'", returnStdout: true).trim()
                copyDBConnJsonFile = sh(script:"ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} 'sudo kubectl -n bvd-helm cp /tmp/dbconnection.json ${wwwPodName}:/tmp/dbconnection.json'", returnStdout: true).trim()
                importDBConnections = sh(script: "ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} 'sudo kubectl -n bvd-helm exec ${wwwPodName} -c bvd-www -- node /bvd/cli/installDBConnections.js --user admin --pass Control@123 --file /tmp/dbconnection.json'", returnStdout: true).trim()
                println "${copyDBConnJsonFile}"
                println "${importDBConnections}"

                sh """
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; chmod 777 uploadWelcome.sh; sudo ./uploadWelcome.sh ${BVD_PORT};"
                  echo -e "\n${ACCESSVM}  ${SYSTEM_HOSTNAME}" >> /etc/hosts
                  echo "Killing any node process if it is already running"
                  kill -9 `pidof node`||true
                  rm -rf ${WORKSPACE}/tools/SecretTool/secrets.json
                  rm -rf ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/*
                  rm -rf ${WORKSPACE}/dashboard/cypress_test_report/
                  export https_proxy="${globals.HTTP_PROXY}";
                  export http_proxy="${globals.HTTP_PROXY}";
                  export BVD_VERTICA_HOST=10.168.179.57
                  export BVD_VERTICA_PORT=5433
                  export BVD_VERTICA_USER=dbadmin
                  export BVD_VERTICA_PW=installed
                  export BVD_VERTICA_DB=opsadb
                  export CYPRESS_username="admin";
                  export CYPRESS_password="Control@123";
                  export CYPRESS_START_OF_THE_WEEK=${cypressStartOfTheWeek};
                  export CYPRESS_baseUrl="https://${SYSTEM_HOSTNAME}:${BVD_PORT}/ui";
                  export CYPRESS_IDM_BASE_URL="https://${SYSTEM_HOSTNAME}:${BVD_PORT}";
                  export CYPRESS_TestEnvironment="systemtest";
                  cd ${WORKSPACE}/dashboard; rm -f ./package-lock.json;

                  echo 'Running BVD on UIF cypress tests'
                  export BVD_SERVICE_URL="https://${SYSTEM_HOSTNAME}:${BVD_PORT}/bvd";

                  cd ${WORKSPACE}/dashboard/test
                  cypress run --spec "cypress/integration/bvd/foundation/bvdOnUIF/*.spec.js" --browser chrome --headless || true
                  [ -d "${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots" ] && cp -r ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots ${WORKSPACE}/dashboard/cypress_test_report/

                  cd ${WORKSPACE}/dashboard
                  chmod +x ./test/utils/uploadFoundationCypressTestData.sh
                  chmod +x ./test/utils/ufc.sh
                  mkdir -p ${WORKSPACE}/dashboard/cypress_test_report/

                  mkdir -p ${WORKSPACE}/dashboard/cypress_reporting_test_report/
                  ./test/utils/uploadFoundationCypressTestData.sh -u admin -p Control@123 -s https://${SYSTEM_HOSTNAME}:${BVD_PORT}/ui -d https://${SYSTEM_HOSTNAME}:${BVD_PORT}
                  ./test/utils/uploadFoundationCypressTestData.sh -u customer2Admin@microfocus.com -p Control@123 -n Customer2 -s https://${SYSTEM_HOSTNAME}:${BVD_PORT}/ui -d https://${SYSTEM_HOSTNAME}:${BVD_PORT}
                  ./test/utils/uploadFoundationCypressTestData.sh -u customer3Admin@microfocus.com -p Control@123 -n Customer3 -s https://${SYSTEM_HOSTNAME}:${BVD_PORT}/ui -d https://${SYSTEM_HOSTNAME}:${BVD_PORT}
                  cd ${WORKSPACE}/dashboard/test
                  echo "start of the week=${cypressStartOfTheWeek}"
                  cypress run --spec "cypress/integration/bvd/foundation/sanity/*.spec.js" --browser chrome --headless || true
                  [ -d "${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots" ] && cp -r ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots ${WORKSPACE}/dashboard/cypress_test_report/
                  cypress run --spec "cypress/integration/bvd/foundation/functional/**/*.spec.js" --browser chrome --headless || true
                  node ${WORKSPACE}/dashboard/node_modules/mochawesome-merge/bin/mochawesome-merge ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/*.json > ${WORKSPACE}/dashboard/cypress_test_report/mochawesome.json
                  node ${WORKSPACE}/dashboard/node_modules/.bin/marge ${WORKSPACE}/dashboard/cypress_test_report/mochawesome.json -f bvd_explore_cypress_tests -o ${WORKSPACE}/dashboard/cypress_test_report/
                  [ -d "${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots" ] && cp -r ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots ${WORKSPACE}/dashboard/cypress_test_report/

                  export CYPRESS_baseUrl="https://${SYSTEM_HOSTNAME}:${BVD_PORT}/bvd";
                  export CYPRESS_receiverUrl="https://${SYSTEM_HOSTNAME}:${BVD_PORT}/bvd-receiver"
                  rm -rf ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/*
                  cypress run --spec "cypress/integration/bvd/reporting/sanity/*.spec.js" --browser chrome --headless || true
                  [ -d "${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots" ] && cp -r ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots ${WORKSPACE}/dashboard/cypress_reporting_test_report/
                  cypress run --spec "cypress/integration/bvd/reporting/functional/**/*.spec.js" --browser chrome --headless || true
                  node ${WORKSPACE}/dashboard/node_modules/mochawesome-merge/bin/mochawesome-merge ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/*.json > ${WORKSPACE}/dashboard/cypress_reporting_test_report/mochawesome.json
                  node ${WORKSPACE}/dashboard/node_modules/.bin/marge ${WORKSPACE}/dashboard/cypress_reporting_test_report/mochawesome.json -f bvd_reporting_cypress_tests -o ${WORKSPACE}/dashboard/cypress_reporting_test_report/
                  [ -d "${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots" ] && cp -r ${WORKSPACE}/dashboard/test/cypress/reports/mochawesome/screenshots ${WORKSPACE}/dashboard/cypress_reporting_test_report/

                  node ${WORKSPACE}/dashboard/test/utils/storeCollectedMetrics.js ${WORKSPACE}/dashboard/test/cachingPerformanceData.json
                """
              }
              container('general-aws') {
                banner('copy test reports to web server')

                sh """
                  export REPORT_FOLDER="${REPORT_FOLDER}"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "mkdir -p /tmp/bvd_cypress_reports"
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
                  put ${WORKSPACE}/dashboard/cypress_test_report/mochawesome.json /tmp/
                  put ${WORKSPACE}/dashboard/cypress_reporting_test_report/mochawesome.json /tmp/bvd_cypress_reports
                  put ${WORKSPACE}/build/tests/cho/getcontents.sh /tmp/
                  bye
                """
                sh """
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo chown root:root mochawesome.json getcontents.sh; sudo chmod 777 mochawesome.json getcontents.sh; sudo chown -R root:root /tmp/bvd_cypress_reports;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo ./getcontents.sh;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo chown centos:centos content.html; sudo chmod 777 content.html;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo chown -R centos:centos /tmp/bvd_cypress_reports;"
                  ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp/bvd_cypress_reports; sudo chown centos:centos content.html; sudo chmod 777 content.html;"

                  rm -rf /tmp/content.html
                  rm -rf /tmp/bvd_cypress_reports/content.html
                  mkdir -p /tmp/bvd_cypress_reports/
                """
                sh """
                  sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
                  lcd /tmp/
                  cd /tmp/
                  get content.html
                  lcd /tmp/bvd_cypress_reports/
                  cd /tmp/bvd_cypress_reports/
                  get content.html
                """
                sh """
                  mkdir -p /report/dashboard/data/UIS/${REPORT_FOLDER}/FOUNDATION/cypress/
                  [ -d "${WORKSPACE}/dashboard/cypress_test_report" ] && cp -r ${WORKSPACE}/dashboard/cypress_test_report/ /report/dashboard/data/UIS/${REPORT_FOLDER}/FOUNDATION/cypress/

                  mkdir -p /report/dashboard/data/UIS/${REPORT_FOLDER}/REPORTING/cypress/
                  [ -d "${WORKSPACE}/dashboard/cypress_reporting_test_report" ] && cp -r ${WORKSPACE}/dashboard/cypress_reporting_test_report/ /report/dashboard/data/UIS/${REPORT_FOLDER}/REPORTING/cypress/
                """
              }
              container('node-build') {
                sh """
                  node ${WORKSPACE}/build/createTestReportIndex.js > /report/dashboard/data/UIS/index.html
                """
              }
            }

            stage('collect coverage') {
              if (COLLECT_COVERAGE == 'true') {
                // collect coverage only if full tests ran, not to loose any coverage
                container ('general-aws') {
                  banner('collect coverage data')
                  PV_NAME = sh(script:"ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} \"sudo find /var/vols/itom/ -path '*/bvd/var/bvd'\"", returnStdout:true).trim()
                  sh """
                    ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} 'sudo -i; sudo kubectl -n \$(sudo kubectl get ns | grep bvd-helm | cut -d " " -f1) scale --replicas=0 deployment/bvd-explore-deployment deployment/bvd-controller-deployment deployment/bvd-www-deployment deployment/bvd-quexserv deployment/bvd-receiver-deployment deployment/webtopdf-deployment;sleep 20;sudo kubectl -n \$(sudo kubectl get ns | grep bvd-helm | cut -d " " -f1) scale --replicas=1 deployment/bvd-explore-deployment deployment/bvd-controller-deployment deployment/bvd-www-deployment deployment/bvd-quexserv deployment/bvd-receiver-deployment deployment/webtopdf-deployment'
                    mkdir -p "/boda/bvd/integration/${globals.BVD_VERSION}/coverage/${REPORT_FOLDER}/cdf${testDBType}"
                    rm -rf "/boda/bvd/integration/${globals.BVD_VERSION}/coverage/${REPORT_FOLDER}/cdf${testDBType}/*"
                    ssh -q ${SSH_GLOBAL_OPTIONS} -p ${PORT} centos@${ACCESSVM} "sudo -i; cd /tmp; sudo chown -R centos:centos ${PV_NAME}/log/coverage;"
                  """
                  sh """
                    sftp -o StrictHostKeyChecking=no -i ssh_key.pem centos@${ACCESSVM} <<-EOF
	                  lcd /boda/bvd/integration/${globals.BVD_VERSION}/coverage/${REPORT_FOLDER}/cdf${testDBType}
	                  cd ${PV_NAME}/log/coverage
	                  get -r *
	                  bye
                  """
                }
              }
            }
          }

          container ('general-aws') {
            emailSubject = "BVD Foundation and Reporting Automated cypress tests success"
            additionalEmailText = additionalEmailText + "<h2>Foundation Cypress tests</h2> \n" + sh(script: "cat /tmp/content.html", returnStdout:true).trim() + "\n\n"
            additionalEmailText = additionalEmailText + "\n\n<h2>Reporting Cypress tests</h2> \n" + sh(script: "cat /tmp/bvd_cypress_reports/content.html",returnStdout:true).trim()
            notifyResults("SUCCESSFUL", additionalEmailText, currentStage, '', 'jitesh.singh@microfocus.com,vijay-kumar.j-v@microfocus.com', emailSubject)
          }
        }
      }
    }
  }
}
catch (error) {
  currentBuild.result = "FAILED"
  emailSubject = "BVD Foundation and Reporting Automated cypress tests with version ${globals.BVD_VERSION}: FAILED"
  notifyResults("FAILED", additionalEmailText, currentStage, error, 'swamilkumar.tyahadi@microfocus.com', emailSubject)

  throw error
}
